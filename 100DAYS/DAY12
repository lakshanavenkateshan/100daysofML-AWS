ðŸ”¹Day 12 â€” Deploy Titanic ML Model via Docker + AWS ECR + EC2

ðŸ”¹What I Did / Goal

Built a Docker image locally with my Flask ML API.

Pushed the image to AWS ECR (Elastic Container Registry) â†’ a cloud registry for Docker images.

Pulled & ran the container on AWS EC2 â†’ running your model in the cloud.

Tested the API from my local machine â†’ got live predictions.

Basically,made my ML app fully production-ready in the cloud, using industry-standard practices.

ðŸ”¹Why I Did This

Cloud deployment practice â†’ In real projects, ML models must run on cloud servers, not just locally.

Versioned container images â†’ ECR stores my Docker images safely and allows re-deployment anywhere.

Scalable & repeatable workflow â†’ Any EC2 instance can now pull my image and run it.

Integration of ML + DevOps â†’ now I know how to take a model from training â†’ Docker â†’ ECR â†’ EC2 â†’ API.

ðŸ”¹How I Did This (Step by Step)

ðŸ”¹Prepare folder

app.py â†’ Flask API

titanic_rf_model.pkl â†’ trained ML model

Dockerfile â†’ Docker image instructions
Code: Refer DAY10

ðŸ”¹Build Docker image locally

docker build -t titanic-flask-app .


Image contains Python + Flask + My model + dependencies.

ðŸ”¹Test Docker image locally

docker run -d -p 5000:5000 titanic-flask-app


Ensure API works â†’ use curl or Postman.

ðŸ”¹Push image to AWS ECR

aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <account>.dkr.ecr.<region>.amazonaws.com
docker tag titanic-flask-app:latest <account>.dkr.ecr.<region>.amazonaws.com/titanic-flask-app:latest
docker push <account>.dkr.ecr.<region>.amazonaws.com/titanic-flask-app:latest


my image is now safely stored in AWS.

ðŸ”¹Pull & run on EC2

docker pull <account>.dkr.ecr.<region>.amazonaws.com/titanic-flask-app:latest
docker run -d -p 5000:5000 --restart unless-stopped <account>.dkr.ecr.<region>.amazonaws.com/titanic-flask-app:latest


EC2 now serves the ML API.

ðŸ”¹Test from my local machine

curl -X POST http://<EC2-IP>:5000/predict -H "Content-Type: application/json" -d "{\"features\": [3,1,22,0,0,7.25]}"


Prediction returned â†’ everything is live and working.

ðŸ”¹What my Learned

How to containerize ML models for portability.

How to use AWS ECR to store Docker images.

How to deploy containers on EC2.

How to access ML APIs from anywhere.

This is a real production workflow used in industry â€” from local development to cloud deployment.
