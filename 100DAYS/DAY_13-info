ğŸ”¹ Day 13 â€“ Deploying Titanic ML Flask App on AWS ECS (Fargate)

ğŸ”¹ What I Did

On Day 13, I deployed my Titanic Survival Prediction Flask API to AWS ECS (Fargate).
This allows the containerized ML model to run in a serverless container service, removing the need to manage EC2 instances manually.

ğŸ”¹ Why I Did It

Running via docker run on EC2 is fine for testing, but not scalable.

ECS Fargate manages containers automatically â†’ no manual container restarts.

It provides auto-scaling, load balancing, and better production-grade deployment.

Helps me learn real-world container orchestration with AWS.

ğŸ”¹ How I Did It
1ï¸âƒ£ Prepared Docker Image

Trained Random Forest model â†’ saved as titanic_rf_model.pkl

Created app.py (Flask app with /predict endpoint)

Created Dockerfile:

FROM python:3.10-slim
WORKDIR /app
COPY app.py titanic_rf_model.pkl /app/
RUN pip install --no-cache-dir flask joblib scikit-learn numpy
EXPOSE 5000
CMD ["python", "app.py"]


Built image locally:

docker build -t titanic-flask-app .


Tagged & pushed to Amazon ECR:

docker tag titanic-flask-app:latest <account_id>.dkr.ecr.ap-south-1.amazonaws.com/titanic-flask-app:latest
docker push <account_id>.dkr.ecr.ap-south-1.amazonaws.com/titanic-flask-app:latest

2ï¸âƒ£ Created ECS Cluster

Opened AWS ECS Console â†’ Create Cluster

Selected Fargate (Networking only)

Named it: titanic-cluster

3ï¸âƒ£ Created Task Definition

New Task Definition â†’ Fargate launch type

Named it: titanic-task

Added container:

Image: <ECR Image URI>

Port: 5000

CPU: 256, Memory: 512

4ï¸âƒ£ Deployed Service

Created ECS Service in titanic-cluster

Used titanic-task definition

Chose Fargate launch type

Enabled public IP

Opened Security Group â†’ allowed inbound traffic on port 5000

5ï¸âƒ£ Tested API

Got Public IP from ECS task

Sent prediction request:

curl -X POST http://<ecs-public-ip>:5000/predict \
-H "Content-Type: application/json" \
-d "{\"features\": [3,1,22,0,0,7.25]}"


ğŸ”¹ Finally:
Received prediction â†’ 0 (did not survive)
